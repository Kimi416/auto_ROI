#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
YOLOè‡ªå‹•ç—…å¤‰æ¤œå‡ºãƒ»åˆ‡ã‚ŠæŠœããƒ„ãƒ¼ãƒ«
å­¦ç¿’æ¸ˆã¿YOLOãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç—…å¤‰ã‚’è‡ªå‹•æ¤œå‡ºã—ã€é€éPNGã§åˆ‡ã‚ŠæŠœã
"""

from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import os
import json
import argparse
from pathlib import Path

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']
matplotlib.rcParams['font.family'] = 'sans-serif'
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class AutoLesionDetector:
    def __init__(self, model_path='best.pt'):
        """
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿YOLOãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        """
        print("ğŸ¤– YOLOè‡ªå‹•ç—…å¤‰æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        if not os.path.exists(model_path):
            # ä»£æ›¿ãƒ‘ã‚¹ã‚’æ¢ã™
            alt_paths = [
                'runs/detect/train/weights/best.pt',
                'runs/detect/train2/weights/best.pt',
                'runs/detect/train3/weights/best.pt',
                'yolo_training/runs/detect/train/weights/best.pt'
            ]
            
            for alt_path in alt_paths:
                if os.path.exists(alt_path):
                    model_path = alt_path
                    break
            else:
                raise FileNotFoundError(f"å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        
        self.model = YOLO(model_path)
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_path}")
        
        # ã‚¯ãƒ©ã‚¹å
        self.class_names = [
            'ADM', 'Ephelis', 'Melasma', 'Solar lentigo',
            'Nevus', 'Basal cell carcinoma', 'Seborrheic keratosis',
            'Malignant melanoma'
        ]
        
    def detect_lesions(self, image_path, conf_threshold=0.5):
        """
        ç”»åƒã‹ã‚‰ç—…å¤‰ã‚’æ¤œå‡º
        
        Args:
            image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            conf_threshold: æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤
            
        Returns:
            results: YOLOæ¤œå‡ºçµæœ
            image: å…ƒç”»åƒï¼ˆnumpy arrayï¼‰
        """
        print(f"\nğŸ” ç—…å¤‰æ¤œå‡ºä¸­: {image_path}")
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # YOLOæ¤œå‡ºå®Ÿè¡Œ
        results = self.model(image_path, conf=conf_threshold)
        
        # æ¤œå‡ºæ•°è¡¨ç¤º
        if len(results[0].boxes) > 0:
            print(f"âœ… {len(results[0].boxes)}å€‹ã®ç—…å¤‰ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        else:
            print("âš ï¸ ç—…å¤‰ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
        return results[0], image_rgb
        
    def visualize_detections(self, image, result, save_path=None):
        """
        æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–
        
        Args:
            image: å…ƒç”»åƒ
            result: YOLOæ¤œå‡ºçµæœ
            save_path: ä¿å­˜ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¡¨ç¤ºã®ã¿ï¼‰
        """
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        ax.imshow(image)
        
        if result.boxes is not None:
            boxes = result.boxes
            
            for i, box in enumerate(boxes):
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹åº§æ¨™
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = box.conf[0].cpu().numpy()
                cls = int(box.cls[0].cpu().numpy())
                
                # çŸ©å½¢æç”»
                rect = patches.Rectangle(
                    (x1, y1), x2-x1, y2-y1,
                    linewidth=2, edgecolor='red', facecolor='none'
                )
                ax.add_patch(rect)
                
                # ãƒ©ãƒ™ãƒ«è¡¨ç¤º
                label = f'{self.class_names[cls]} {conf:.2f}'
                ax.text(x1, y1-5, label, 
                       bbox=dict(boxstyle="round,pad=0.3", facecolor='yellow', alpha=0.7),
                       fontsize=10)
        
        ax.set_title(f'è‡ªå‹•ç—…å¤‰æ¤œå‡ºçµæœ ({len(boxes) if result.boxes is not None else 0}å€‹æ¤œå‡º)')
        ax.axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ“¸ æ¤œå‡ºçµæœä¿å­˜: {save_path}")
        else:
            plt.show()
            
    def extract_lesions(self, image_path, output_dir='extracted_lesions', conf_threshold=0.5):
        """
        æ¤œå‡ºã—ãŸç—…å¤‰ã‚’å€‹åˆ¥ã«åˆ‡ã‚ŠæŠœã„ã¦é€éPNGã§ä¿å­˜
        
        Args:
            image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            conf_threshold: æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤
            
        Returns:
            extracted_count: åˆ‡ã‚ŠæŠœã„ãŸç—…å¤‰æ•°
        """
        # æ¤œå‡ºå®Ÿè¡Œ
        result, image_rgb = self.detect_lesions(image_path, conf_threshold)
        
        if result.boxes is None or len(result.boxes) == 0:
            return 0
            
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        # PILç”»åƒã«å¤‰æ›
        pil_image = Image.fromarray(image_rgb)
        base_name = Path(image_path).stem
        
        extracted_info = []
        
        for i, box in enumerate(result.boxes):
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹åº§æ¨™
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
            conf = box.conf[0].cpu().numpy()
            cls = int(box.cls[0].cpu().numpy())
            
            # ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ ï¼ˆ10%ï¼‰
            h, w = image_rgb.shape[:2]
            margin = 0.1
            dx = int((x2 - x1) * margin)
            dy = int((y2 - y1) * margin)
            
            x1 = max(0, x1 - dx)
            y1 = max(0, y1 - dy)
            x2 = min(w, x2 + dx)
            y2 = min(h, y2 + dy)
            
            # ç—…å¤‰éƒ¨åˆ†ã‚’åˆ‡ã‚ŠæŠœã
            lesion_crop = pil_image.crop((x1, y1, x2, y2))
            
            # é€éPNGä½œæˆï¼ˆæ¥•å††å½¢ãƒã‚¹ã‚¯ï¼‰
            mask = Image.new('L', lesion_crop.size, 0)
            from PIL import ImageDraw
            draw = ImageDraw.Draw(mask)
            
            # æ¥•å††å½¢ãƒã‚¹ã‚¯ä½œæˆ
            draw.ellipse([0, 0, lesion_crop.size[0], lesion_crop.size[1]], fill=255)
            
            # RGBAç”»åƒä½œæˆ
            rgba_image = lesion_crop.convert('RGBA')
            rgba_image.putalpha(mask)
            
            # ä¿å­˜
            output_path = os.path.join(
                output_dir, 
                f"{base_name}_lesion_{i+1}_{self.class_names[cls]}.png"
            )
            rgba_image.save(output_path)
            
            # æƒ…å ±è¨˜éŒ²
            extracted_info.append({
                'index': i + 1,
                'class': self.class_names[cls],
                'confidence': float(conf),
                'bbox': {
                    'x': int(x1),
                    'y': int(y1),
                    'width': int(x2 - x1),
                    'height': int(y2 - y1)
                },
                'output_file': os.path.basename(output_path)
            })
            
        # æŠ½å‡ºæƒ…å ±ã‚’ä¿å­˜
        info_path = os.path.join(output_dir, f"{base_name}_extraction_info.json")
        with open(info_path, 'w') as f:
            json.dump({
                'source_image': image_path,
                'total_lesions': len(extracted_info),
                'conf_threshold': conf_threshold,
                'lesions': extracted_info
            }, f, indent=2)
            
        print(f"âœ… {len(extracted_info)}å€‹ã®ç—…å¤‰ã‚’åˆ‡ã‚ŠæŠœãã¾ã—ãŸ")
        print(f"ğŸ“ ä¿å­˜å…ˆ: {output_dir}")
        
        return len(extracted_info)
        
    def process_directory(self, input_dir, output_dir='extracted_lesions', 
                         conf_threshold=0.5, visualize=False):
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ç”»åƒã‚’å‡¦ç†
        
        Args:
            input_dir: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            conf_threshold: æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤
            visualize: æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–ã™ã‚‹ã‹
        """
        input_path = Path(input_dir)
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åé›†
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        image_files = []
        for ext in image_extensions:
            image_files.extend(input_path.glob(ext))
            
        if not image_files:
            print(f"âš ï¸ {input_dir} ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        print(f"\nğŸ“‚ {len(image_files)}æšã®ç”»åƒã‚’å‡¦ç†ã—ã¾ã™")
        
        total_extracted = 0
        results_summary = []
        
        for img_path in image_files:
            print(f"\nå‡¦ç†ä¸­: {img_path.name}")
            
            try:
                # ç—…å¤‰æŠ½å‡º
                count = self.extract_lesions(
                    str(img_path), 
                    output_dir=output_dir,
                    conf_threshold=conf_threshold
                )
                total_extracted += count
                
                # å¯è¦–åŒ–
                if visualize:
                    result, image_rgb = self.detect_lesions(str(img_path), conf_threshold)
                    viz_path = os.path.join(output_dir, f"{img_path.stem}_detection.jpg")
                    self.visualize_detections(image_rgb, result, save_path=viz_path)
                    
                results_summary.append({
                    'image': img_path.name,
                    'lesions_detected': count,
                    'status': 'success'
                })
                
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                results_summary.append({
                    'image': img_path.name,
                    'lesions_detected': 0,
                    'status': 'error',
                    'error': str(e)
                })
                
        # ã‚µãƒãƒªãƒ¼ä¿å­˜
        summary_path = os.path.join(output_dir, 'processing_summary.json')
        with open(summary_path, 'w') as f:
            json.dump({
                'total_images': len(image_files),
                'total_lesions_extracted': total_extracted,
                'conf_threshold': conf_threshold,
                'results': results_summary
            }, f, indent=2)
            
        print(f"\nğŸ‰ å‡¦ç†å®Œäº†!")
        print(f"ğŸ“Š çµæœ: {len(image_files)}æšã®ç”»åƒã‹ã‚‰{total_extracted}å€‹ã®ç—…å¤‰ã‚’æŠ½å‡º")
        print(f"ğŸ“ ä¿å­˜å…ˆ: {output_dir}")

def main():
    parser = argparse.ArgumentParser(description='YOLOè‡ªå‹•ç—…å¤‰æ¤œå‡ºãƒ»åˆ‡ã‚ŠæŠœããƒ„ãƒ¼ãƒ«')
    parser.add_argument('input', help='å…¥åŠ›ç”»åƒã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹')
    parser.add_argument('-m', '--model', default='best.pt', help='YOLOãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('-o', '--output', default='extracted_lesions', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('-c', '--conf', type=float, default=0.5, help='æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤ (0-1)')
    parser.add_argument('-v', '--visualize', action='store_true', help='æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–')
    
    args = parser.parse_args()
    
    # æ¤œå‡ºå™¨åˆæœŸåŒ–
    detector = AutoLesionDetector(model_path=args.model)
    
    input_path = Path(args.input)
    
    if input_path.is_file():
        # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        count = detector.extract_lesions(
            str(input_path),
            output_dir=args.output,
            conf_threshold=args.conf
        )
        
        if args.visualize:
            result, image_rgb = detector.detect_lesions(str(input_path), args.conf)
            detector.visualize_detections(image_rgb, result)
            
    elif input_path.is_dir():
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‡¦ç†
        detector.process_directory(
            str(input_path),
            output_dir=args.output,
            conf_threshold=args.conf,
            visualize=args.visualize
        )
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {input_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

if __name__ == "__main__":
    main()