#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
YOLOv8ç—…å¤‰æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
- ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
- YOLOv8å­¦ç¿’å®Ÿè¡Œ
- æ¤œå‡ºç²¾åº¦ãƒ†ã‚¹ãƒˆ
"""

import os
import shutil
import yaml
from pathlib import Path
from ultralytics import YOLO
import cv2
import numpy as np
import random
import argparse
import json
from datetime import datetime

class LesionYOLOTrainer:
    def __init__(self, images_dir, annotations_dir, output_dir="yolo_dataset"):
        self.images_dir = Path(images_dir)
        self.annotations_dir = Path(annotations_dir)
        self.output_dir = Path(output_dir)
        
        # ç—…å¤‰ã‚¿ã‚¤ãƒ—å®šç¾©
        self.disease_classes = [
            'Melasma',              # 0. è‚æ–‘
            'Solar_lentigo',        # 1. æ—¥å…‰æ€§è‰²ç´ æ–‘
            'Nevus',                # 2. æ¯æ–‘
            'ADM',                  # 3. å¾Œå¤©æ€§çœŸçš®ãƒ¡ãƒ©ãƒã‚µã‚¤ãƒˆãƒ¼ã‚·ã‚¹
            'Ephelis',              # 4. é›€åµæ–‘
            'Seborrheic_keratosis', # 5. è„‚æ¼æ€§è§’åŒ–ç—‡
            'Basal_cell_carcinoma', # 6. åŸºåº•ç´°èƒç™Œï¼ˆBCCï¼‰
            'Malignant_melanoma'    # 7. æ‚ªæ€§é»’è‰²è…«
        ]
        
        self.setup_directories()
    
    def setup_directories(self):
        """YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ ã‚’ä½œæˆ"""
        print("YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ ã‚’ä½œæˆä¸­...")
        
        # ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        for split in ['train', 'val', 'test']:
            (self.output_dir / split / 'images').mkdir(parents=True, exist_ok=True)
            (self.output_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        # çµæœä¿å­˜ç”¨
        (self.output_dir / 'models').mkdir(exist_ok=True)
        (self.output_dir / 'results').mkdir(exist_ok=True)
        
        print(f"ğŸ“ å‡ºåŠ›å…ˆ: {self.output_dir}")
    
    def create_dataset_config(self):
        """YOLOè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        config = {
            'path': str(self.output_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images', 
            'test': 'test/images',
            'nc': len(self.disease_classes),
            'names': {i: name for i, name in enumerate(self.disease_classes)}
        }
        
        config_path = self.output_dir / 'dataset.yaml'
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {config_path}")
        return config_path
    
    def prepare_dataset(self, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ã¨ã‚³ãƒ”ãƒ¼"""
        print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ä¸­...")
        
        # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¸ˆã¿ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’å–å¾—
        label_files = list((self.annotations_dir / 'labels').glob('*.txt'))
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        
        valid_pairs = []
        for label_file in label_files:
            # å¯¾å¿œã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™ï¼ˆå†å¸°çš„ã«æ¤œç´¢ï¼‰
            base_name = label_file.stem
            image_file = None
            
            # organized_maskedå†…ã®å…¨ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç”»åƒã‚’æ¢ã™
            for ext in image_extensions:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³: base_name.ext
                potential_images = list(self.images_dir.rglob(f"{base_name}{ext}"))
                if potential_images:
                    image_file = potential_images[0]  # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸç”»åƒ
                    break
            
            if image_file:
                valid_pairs.append((image_file, label_file))
        
        print(f"æœ‰åŠ¹ãªç”»åƒ-ãƒ©ãƒ™ãƒ«ãƒšã‚¢: {len(valid_pairs)}çµ„")
        
        if len(valid_pairs) == 0:
            raise ValueError("æœ‰åŠ¹ãªç”»åƒ-ãƒ©ãƒ™ãƒ«ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ï¼‰
        random.seed(42)
        shuffled_pairs = valid_pairs.copy()
        random.shuffle(shuffled_pairs)
        
        total = len(shuffled_pairs)
        test_size = int(total * test_ratio)
        val_size = int(total * val_ratio)
        train_size = total - test_size - val_size
        
        train_data = shuffled_pairs[:train_size]
        val_data = shuffled_pairs[train_size:train_size + val_size]
        test_data = shuffled_pairs[train_size + val_size:]
        
        # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼
        splits = {
            'train': train_data,
            'val': val_data, 
            'test': test_data
        }
        
        for split_name, data_list in splits.items():
            print(f"ğŸ“¦ {split_name}ãƒ‡ãƒ¼ã‚¿: {len(data_list)}å€‹")
            
            for img_path, label_path in data_list:
                # ç”»åƒã‚³ãƒ”ãƒ¼
                dst_img = self.output_dir / split_name / 'images' / img_path.name
                shutil.copy2(img_path, dst_img)
                
                # ãƒ©ãƒ™ãƒ«ã‚³ãƒ”ãƒ¼
                dst_label = self.output_dir / split_name / 'labels' / label_path.name
                shutil.copy2(label_path, dst_label)
        
        return len(train_data), len(val_data), len(test_data)
    
    def train_model(self, model_size='n', epochs=100, batch_size=16, patience=10):
        """YOLOv8ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        print(f"YOLOv8{model_size}ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        config_path = self.create_dataset_config()
        
        # YOLOãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        model = YOLO(f'yolov8{model_size}.pt')
        
        # å­¦ç¿’å®Ÿè¡Œ
        results = model.train(
            data=str(config_path),
            epochs=epochs,
            batch=batch_size,
            imgsz=640,
            patience=patience,
            device='cpu',  # GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯'0'ã«å¤‰æ›´
            project=str(self.output_dir / 'models'),
            name='lesion_detection',
            exist_ok=True,
            verbose=True,
            plots=True,
            save_period=10
        )
        
        print("âœ… å­¦ç¿’å®Œäº†")
        return results
    
    def evaluate_model(self, model_path=None):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"""
        if model_path is None:
            # æœ€æ–°ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            model_path = self.output_dir / 'models' / 'lesion_detection' / 'weights' / 'best.pt'
        
        if not Path(model_path).exists():
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        
        print(f"ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­: {model_path}")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model = YOLO(str(model_path))
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
        test_images_dir = self.output_dir / 'test' / 'images'
        if not test_images_dir.exists() or not list(test_images_dir.glob('*')):
            print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ã¾ã™ã€‚")
            test_images_dir = self.output_dir / 'val' / 'images'
        
        # è©•ä¾¡å®Ÿè¡Œ
        results = model.val(data=str(self.create_dataset_config()))
        
        print("ğŸ“Š è©•ä¾¡çµæœ:")
        print(f"mAP50: {results.box.map50:.3f}")
        print(f"mAP50-95: {results.box.map:.3f}")
        
        return results
    
    def test_detection(self, model_path=None, test_image_path=None):
        """å€‹åˆ¥ç”»åƒã§ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        if model_path is None:
            model_path = self.output_dir / 'models' / 'lesion_detection' / 'weights' / 'best.pt'
        
        if not Path(model_path).exists():
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model = YOLO(str(model_path))
        
        # ãƒ†ã‚¹ãƒˆç”»åƒé¸æŠ
        if test_image_path is None:
            test_images = list((self.output_dir / 'test' / 'images').glob('*'))
            if not test_images:
                test_images = list((self.output_dir / 'val' / 'images').glob('*'))
            if test_images:
                test_image_path = test_images[0]
        
        if test_image_path is None:
            print("ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        print(f"ğŸ” ãƒ†ã‚¹ãƒˆç”»åƒ: {test_image_path}")
        
        # æ¨è«–å®Ÿè¡Œ
        results = model(str(test_image_path))
        
        # çµæœè¡¨ç¤º
        for r in results:
            print(f"æ¤œå‡ºæ•°: {len(r.boxes)} å€‹")
            for box in r.boxes:
                class_id = int(box.cls[0])
                confidence = float(box.conf[0])
                class_name = self.disease_classes[class_id]
                print(f"- {class_name}: {confidence:.3f}")
        
        # çµæœç”»åƒä¿å­˜
        output_path = self.output_dir / 'results' / f'detection_result_{Path(test_image_path).name}'
        results[0].save(str(output_path))
        print(f"ğŸ’¾ çµæœä¿å­˜: {output_path}")
        
        return results
    
    def generate_report(self):
        """å­¦ç¿’ãƒ»è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'dataset_info': {
                'classes': self.disease_classes,
                'total_classes': len(self.disease_classes)
            },
            'paths': {
                'images_dir': str(self.images_dir),
                'annotations_dir': str(self.annotations_dir),
                'output_dir': str(self.output_dir)
            }
        }
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ
        for split in ['train', 'val', 'test']:
            split_dir = self.output_dir / split / 'images'
            if split_dir.exists():
                count = len(list(split_dir.glob('*')))
                report['dataset_info'][f'{split}_count'] = count
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = self.output_dir / 'training_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        return report

def main():
    parser = argparse.ArgumentParser(description='YOLOv8ç—…å¤‰æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ')
    parser.add_argument('images_dir', help='ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('-a', '--annotations', default='yolo_annotations', help='ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('-o', '--output', default='yolo_dataset', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('-m', '--model', default='n', choices=['n', 's', 'm', 'l', 'x'], help='ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º')
    parser.add_argument('-e', '--epochs', type=int, default=100, help='å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--batch', type=int, default=16, help='ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--eval-only', action='store_true', help='è©•ä¾¡ã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--test-only', action='store_true', help='ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
    trainer = LesionYOLOTrainer(args.images_dir, args.annotations, args.output)
    
    if args.test_only:
        # ãƒ†ã‚¹ãƒˆã®ã¿
        trainer.test_detection()
    elif args.eval_only:
        # è©•ä¾¡ã®ã¿
        trainer.evaluate_model()
    else:
        # å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        print("ğŸš€ YOLOv8ç—…å¤‰æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
        train_count, val_count, test_count = trainer.prepare_dataset()
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²: train={train_count}, val={val_count}, test={test_count}")
        
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        trainer.train_model(
            model_size=args.model,
            epochs=args.epochs,
            batch_size=args.batch
        )
        
        # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        trainer.evaluate_model()
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        trainer.test_detection()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        trainer.generate_report()
        
        print("âœ… å…¨å‡¦ç†å®Œäº†")

if __name__ == '__main__':
    main()