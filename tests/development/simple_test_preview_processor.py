#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
test_preview.jpgã®ç—…å¤‰æ¤œå‡ºï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
dlibãªã—ã§ã‚‚å®Ÿè¡Œå¯èƒ½
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO

def detect_lesions_in_test_preview():
    """
    test_preview.jpgã‹ã‚‰ç—…å¤‰ã‚’æ¤œå‡ºã—ã€çµæœã‚’å¯è¦–åŒ–
    """
    print("ğŸ¯ test_preview.jpg ç—…å¤‰æ¤œå‡ºé–‹å§‹")
    print("=" * 60)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    image_path = "test_preview.jpg"
    model_path = "fast_lesion_training/training_runs/fast_lesion_20250806_095404/weights/best.pt"
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    model = YOLO(model_path)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    
    # ç”»åƒèª­ã¿è¾¼ã¿
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {image_path}")
        return
    
    print(f"âœ… ç”»åƒèª­ã¿è¾¼ã¿å®Œäº†: {image.shape[1]} x {image.shape[0]}")
    
    # BGR -> RGBå¤‰æ›
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # ã‚¯ãƒ©ã‚¹å®šç¾©
    pad_classes = ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']
    class_names_jp = {
        'ACK': 'æ—¥å…‰è§’åŒ–ç—‡',
        'BCC': 'åŸºåº•ç´°èƒç™Œ', 
        'MEL': 'æ‚ªæ€§é»’è‰²è…«',
        'NEV': 'è‰²ç´ æ€§æ¯æ–‘',
        'SCC': 'æœ‰æ£˜ç´°èƒç™Œ',
        'SEK': 'è„‚æ¼æ€§è§’åŒ–ç—‡'
    }
    
    # è‰²å®šç¾©ï¼ˆBGRï¼‰
    colors_bgr = {
        'ACK': (0, 255, 0),      # ç·‘
        'BCC': (0, 0, 255),      # èµ¤
        'MEL': (255, 0, 255),    # ãƒã‚¼ãƒ³ã‚¿
        'NEV': (255, 255, 0),    # ã‚·ã‚¢ãƒ³
        'SCC': (0, 165, 255),    # ã‚ªãƒ¬ãƒ³ã‚¸
        'SEK': (128, 0, 128)     # ç´«
    }
    
    # è¤‡æ•°ã®ä¿¡é ¼åº¦ã§æ¨è«–ï¼ˆè¶…ä½ä¿¡é ¼åº¦ã‚‚å«ã‚€ï¼‰
    confidence_levels = [0.01, 0.05, 0.1, 0.15, 0.2]
    best_detections = []
    best_conf = 0.1
    
    for conf_threshold in confidence_levels:
        print(f"ğŸ” ä¿¡é ¼åº¦ {conf_threshold} ã§æ¨è«–å®Ÿè¡Œ...")
        results = model(image_path, conf=conf_threshold, verbose=False)
        
        detections = []
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    cls_id = int(box.cls[0])
                    conf = float(box.conf[0])
                    class_name = pad_classes[cls_id]
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    
                    detections.append({
                        'class': class_name,
                        'class_jp': class_names_jp[class_name],
                        'confidence': conf,
                        'bbox': [x1, y1, x2, y2]
                    })
        
        print(f"  æ¤œå‡ºæ•°: {len(detections)}")
        if detections:
            best_detections = detections
            best_conf = conf_threshold
            break
    
    # çµæœè¡¨ç¤º
    print(f"\\nğŸ“Š æœ€çµ‚æ¤œå‡ºçµæœ (ä¿¡é ¼åº¦: {best_conf}):")
    if best_detections:
        print(f"  æ¤œå‡ºã•ã‚ŒãŸç—…å¤‰æ•°: {len(best_detections)}")
        
        # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        best_detections.sort(key=lambda x: x['confidence'], reverse=True)
        
        # å¯è¦–åŒ–ç”¨ç”»åƒä½œæˆ
        annotated_image = image.copy()
        
        for i, det in enumerate(best_detections, 1):
            x1, y1, x2, y2 = det['bbox']
            class_name = det['class']
            class_name_jp = det['class_jp']
            conf = det['confidence']
            color = colors_bgr[class_name]
            
            print(f"  {i}. {class_name_jp} ({class_name})")
            print(f"     ä¿¡é ¼åº¦: {conf:.3f}")
            print(f"     ä½ç½®: ({x1}, {y1}) - ({x2}, {y2})")
            print(f"     ã‚µã‚¤ã‚º: {x2-x1}px Ã— {y2-y1}px")
            print()
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»ï¼ˆå¤ªç·šï¼‰
            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 5)
            
            # ãƒ©ãƒ™ãƒ«æç”»
            label = f"{i}. {class_name} {conf:.3f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
            
            # ãƒ©ãƒ™ãƒ«ä½ç½®èª¿æ•´
            label_y = y1 - 15
            if label_y < 30:
                label_y = y2 + 40
                
            # ãƒ©ãƒ™ãƒ«èƒŒæ™¯
            cv2.rectangle(annotated_image, 
                        (x1, label_y - label_size[1] - 10), 
                        (x1 + label_size[0] + 10, label_y + 5), 
                        color, -1)
            
            # ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
            cv2.putText(annotated_image, label, (x1 + 5, label_y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            
            # ä¸­å¤®ã«ç•ªå·è¡¨ç¤º
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            cv2.circle(annotated_image, (center_x, center_y), 25, color, -1)
            cv2.putText(annotated_image, str(i), (center_x-12, center_y+12), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
        
        # çµæœä¿å­˜
        cv2.imwrite("test_preview_lesion_detection_result.jpg", annotated_image)
        print("ğŸ’¾ ç—…å¤‰æ¤œå‡ºçµæœä¿å­˜: test_preview_lesion_detection_result.jpg")
        
        # æ¯”è¼ƒå¯è¦–åŒ–ä½œæˆ
        create_comparison_visualization(image_rgb, annotated_image, best_detections)
        
    else:
        print("  æ¤œå‡ºã•ã‚ŒãŸç—…å¤‰ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return best_detections

def create_comparison_visualization(original_rgb, annotated_bgr, detections):
    """
    æ¯”è¼ƒå¯è¦–åŒ–ã‚’ä½œæˆ
    """
    annotated_rgb = cv2.cvtColor(annotated_bgr, cv2.COLOR_BGR2RGB)
    
    # 2åˆ—æ¯”è¼ƒè¡¨ç¤º
    fig, axes = plt.subplots(1, 2, figsize=(20, 10))
    
    # å…ƒç”»åƒ
    axes[0].imshow(original_rgb)
    axes[0].set_title('Original Image (test_preview.jpg)', fontsize=16, fontweight='bold')
    axes[0].set_xticks([])
    axes[0].set_yticks([])
    
    # ç—…å¤‰æ¤œå‡ºçµæœ
    axes[1].imshow(annotated_rgb)
    axes[1].set_title(f'Lesion Detection Results\\n({len(detections)} lesions detected)', 
                     fontsize=16, fontweight='bold')
    axes[1].set_xticks([])
    axes[1].set_yticks([])
    
    # å‡¡ä¾‹ä½œæˆ
    if detections:
        colors_rgb = {
            'ACK': (0, 1, 0),        # ç·‘
            'BCC': (1, 0, 0),        # èµ¤
            'MEL': (1, 0, 1),        # ãƒã‚¼ãƒ³ã‚¿
            'NEV': (0, 1, 1),        # ã‚·ã‚¢ãƒ³
            'SCC': (1, 0.5, 0),      # ã‚ªãƒ¬ãƒ³ã‚¸
            'SEK': (0.5, 0, 0.5)     # ç´«
        }
        
        legend_elements = []
        for i, det in enumerate(detections, 1):
            class_name = det['class']
            class_name_jp = det['class_jp']
            conf = det['confidence']
            color = colors_rgb[class_name]
            
            legend_elements.append(plt.Rectangle((0,0),1,1, facecolor=color, 
                                               label=f"{i}. {class_name_jp} ({class_name}) - {conf:.3f}"))
        
        axes[1].legend(handles=legend_elements, loc='upper right', 
                      bbox_to_anchor=(1, 1), fontsize=12)
    
    plt.tight_layout()
    plt.savefig("test_preview_comparison_visualization.png", dpi=300, bbox_inches='tight')
    print("ğŸ’¾ æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜: test_preview_comparison_visualization.png")
    plt.show()

if __name__ == "__main__":
    detections = detect_lesions_in_test_preview()
    
    print(f"\\nğŸ‰ test_preview.jpg ç—…å¤‰æ¤œå‡ºå®Œäº†!")
    if detections:
        print(f"ğŸ“Š æ¤œå‡ºçµæœã¾ã¨ã‚:")
        for i, det in enumerate(detections, 1):
            print(f"  {i}. {det['class_jp']} - ä¿¡é ¼åº¦: {det['confidence']:.3f}")
    else:
        print("âŒ ç—…å¤‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")