#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Phase 2 ç²¾åº¦å‘ä¸Šç‰ˆ
å®‰å®šã—ãŸPhase 2åŸºç›¤ã§ç²¾åº¦ã‚’æœ€å¤§åŒ–
"""

from ultralytics import YOLO
import torch
import gc
import json
import numpy as np
from pathlib import Path

def analyze_dataset_quality():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªåˆ†æ"""
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªåˆ†æ")
    
    with open('yolo_annotations.json', 'r') as f:
        annotations = json.load(f)
    
    # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒåˆ†æ
    class_counts = {}
    bbox_sizes = []
    
    for ann in annotations:
        category = ann['category']
        class_counts[category] = class_counts.get(category, 0) + ann['lesion_count']
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºåˆ†æï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
        if 'bbox_info' in ann:
            bbox_sizes.extend(ann['bbox_info'])
    
    print("ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ:")
    total_samples = sum(class_counts.values())
    for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_samples) * 100
        print(f"  {cls}: {count}å€‹ ({percentage:.1f}%)")
    
    # ä¸å‡è¡¡åº¦è¨ˆç®—
    max_count = max(class_counts.values())
    min_count = min(class_counts.values())
    imbalance_ratio = max_count / min_count
    
    print(f"\\nãƒ‡ãƒ¼ã‚¿ä¸å‡è¡¡æ¯”: {imbalance_ratio:.1f}:1")
    if imbalance_ratio > 10:
        print("âš ï¸ é‡åº¦ã®ä¸å‡è¡¡ - é‡ã¿èª¿æ•´å¿…è¦")
    elif imbalance_ratio > 3:
        print("âš ï¸ ä¸­åº¦ã®ä¸å‡è¡¡ - è»½ã„é‡ã¿èª¿æ•´æ¨å¥¨")
    
    return class_counts

def calculate_optimized_class_weights(class_counts):
    """æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹é‡ã¿è¨ˆç®—"""
    
    class_mapping = {
        'ADM': 0, 'Ephelis': 1, 'Melasma': 2, 'Solar lentigo': 3,
        'Nevus': 4, 'Basal cell carcinoma': 5, 'Seborrheic keratosis': 6,
        'Malignant melanoma': 7
    }
    
    total_samples = sum(class_counts.values())
    class_weights = {}
    
    # ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸé‡ã¿è¨ˆç®—
    for cat, class_id in class_mapping.items():
        count = class_counts.get(cat, 1)
        # sqrté‡ã¿ã§æ¥µç«¯ãªé‡ã¿ä»˜ã‘ã‚’é¿ã‘ã‚‹
        weight = np.sqrt(total_samples / (len(class_mapping) * count))
        class_weights[class_id] = weight
    
    print("\\næœ€é©åŒ–ã‚¯ãƒ©ã‚¹é‡ã¿:")
    for cat, class_id in class_mapping.items():
        weight = class_weights[class_id]
        print(f"  {cat}: {weight:.3f}")
    
    return class_weights

def train_phase2_precision_boost():
    """Phase 2 ç²¾åº¦å‘ä¸Šç‰ˆ"""
    print("ğŸš€ Phase 2 ç²¾åº¦å‘ä¸Šç‰ˆé–‹å§‹")
    print("="*60)
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†æ
    class_counts = analyze_dataset_quality()
    class_weights = calculate_optimized_class_weights(class_counts)
    
    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
    gc.collect()
    if torch.backends.mps.is_available():
        torch.mps.empty_cache()
    
    # æ–°ã—ã„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ï¼ˆã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ï¼‰
    print("\\nğŸ“ ãƒ¢ãƒ‡ãƒ«é¸æŠ: YOLOv8l (å¤§å‹ãƒ¢ãƒ‡ãƒ«)")
    model = YOLO('yolov8l.pt')  # largeãƒ¢ãƒ‡ãƒ«ã§ç²¾åº¦å‘ä¸Š
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = 'mps' if torch.backends.mps.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸ ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    print("\\nâš™ï¸ ç²¾åº¦æœ€é©åŒ–è¨­å®š:")
    print("- ãƒ¢ãƒ‡ãƒ«: YOLOv8l (é«˜ç²¾åº¦)")
    print("- ã‚¨ãƒãƒƒã‚¯: 30 (ååˆ†ãªå­¦ç¿’)")
    print("- ãƒãƒƒãƒã‚µã‚¤ã‚º: 4 (ç²¾åº¦é‡è¦–)")
    print("- ç”»åƒã‚µã‚¤ã‚º: 640 (æ¨™æº–)")
    print("- æœ€é©åŒ–å™¨: AdamW")
    print("- å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°: Cosine")
    
    try:
        results = model.train(
            data='lesion_detection.yaml',
            epochs=30,  # ååˆ†ãªå­¦ç¿’
            imgsz=640,
            batch=4,    # ç²¾åº¦é‡è¦–ã®å°ãƒãƒƒãƒ
            device=device,
            optimizer='AdamW',
            lr0=0.001,  # åˆæœŸå­¦ç¿’ç‡
            lrf=0.01,   # æœ€çµ‚å­¦ç¿’ç‡æ¯”
            momentum=0.937,
            weight_decay=0.0005,
            warmup_epochs=3,    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
            warmup_momentum=0.8,
            warmup_bias_lr=0.1,
            # æå¤±é‡ã¿æœ€é©åŒ–
            box=7.5,    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æå¤±
            cls=2.0,    # ã‚¯ãƒ©ã‚¹åˆ†é¡æå¤±é‡è¦–
            dfl=1.5,    # åˆ†å¸ƒç„¦ç‚¹æå¤±
            # é«˜ç²¾åº¦ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            hsv_h=0.015,    # è‰²ç›¸
            hsv_s=0.7,      # å½©åº¦
            hsv_v=0.4,      # æ˜åº¦
            translate=0.1,   # ç§»å‹•
            scale=0.5,      # ã‚¹ã‚±ãƒ¼ãƒ«
            mosaic=1.0,     # ãƒ¢ã‚¶ã‚¤ã‚¯æœ€å¤§
            mixup=0.1,      # ãƒŸãƒƒã‚¯ã‚¹ã‚¢ãƒƒãƒ—
            copy_paste=0.1, # ã‚³ãƒ”ãƒ¼ãƒšãƒ¼ã‚¹ãƒˆ
            # å­¦ç¿’åˆ¶å¾¡
            patience=15,    # æ—©æœŸåœæ­¢
            save=True,
            save_period=5,  # 5ã‚¨ãƒãƒƒã‚¯ã”ã¨ä¿å­˜
            val=True,
            plots=True,
            exist_ok=True,
            project='runs/detect',
            name='phase2_precision_boost',
            workers=4,
            verbose=True,
            # Test Time Augmentation
            augment=True,   # æ¨è«–æ™‚æ‹¡å¼µ
            # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰è¨­å®š
            cos_lr=True,    # Cosineå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
            close_mosaic=10 # æœ€å¾Œã®10ã‚¨ãƒãƒƒã‚¯ã¯ãƒ¢ã‚¶ã‚¤ã‚¯ç„¡åŠ¹
        )
        
        print("âœ… Phase 2 ç²¾åº¦å‘ä¸Šç‰ˆå®Œäº†!")
        return 'runs/detect/phase2_precision_boost/weights/best.pt'
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_results():
    """çµæœæ¯”è¼ƒ"""
    try:
        import pandas as pd
        
        print("\\nğŸ“Š æ€§èƒ½æ¯”è¼ƒ")
        print("="*50)
        
        # å…ƒã®Phase 2
        original_df = pd.read_csv('runs/detect/optimal_stable_phase2/results.csv')
        original_final = original_df.iloc[-1]
        
        print("Phase 2 å…ƒç‰ˆ:")
        print(f"  mAP50: {original_final['metrics/mAP50(B)']:.4f}")
        print(f"  mAP50-95: {original_final['metrics/mAP50-95(B)']:.4f}")
        print(f"  Precision: {original_final['metrics/precision(B)']:.4f}")
        print(f"  Recall: {original_final['metrics/recall(B)']:.4f}")
        
        # ç²¾åº¦å‘ä¸Šç‰ˆ
        if Path('runs/detect/phase2_precision_boost/results.csv').exists():
            boost_df = pd.read_csv('runs/detect/phase2_precision_boost/results.csv')
            boost_final = boost_df.iloc[-1]
            
            print("\\nPhase 2 ç²¾åº¦å‘ä¸Šç‰ˆ:")
            print(f"  mAP50: {boost_final['metrics/mAP50(B)']:.4f}")
            print(f"  mAP50-95: {boost_final['metrics/mAP50-95(B)']:.4f}")
            print(f"  Precision: {boost_final['metrics/precision(B)']:.4f}")
            print(f"  Recall: {boost_final['metrics/recall(B)']:.4f}")
            
            # æ”¹å–„åº¦
            map50_improvement = boost_final['metrics/mAP50(B)'] - original_final['metrics/mAP50(B)']
            precision_improvement = boost_final['metrics/precision(B)'] - original_final['metrics/precision(B)']
            
            print(f"\\nğŸ¯ æ”¹å–„åº¦:")
            print(f"  mAP50: {map50_improvement:+.4f}")
            print(f"  Precision: {precision_improvement:+.4f}")
            
            if map50_improvement > 0.02:
                print("ğŸ‰ å¤§å¹…æ”¹å–„é”æˆ!")
            elif map50_improvement > 0:
                print("âœ… æ”¹å–„ç¢ºèª")
            else:
                print("âš ï¸ æ”¹å–„ãªã—")
                
    except Exception as e:
        print(f"æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")

def main():
    print("ğŸ¯ Phase 2 ç²¾åº¦å‘ä¸Šãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    print("å¤§å‹ãƒ¢ãƒ‡ãƒ« + æœ€é©åŒ–è¨­å®šã§ç²¾åº¦æœ€å¤§åŒ–")
    
    result = train_phase2_precision_boost()
    
    if result:
        print(f"\\nğŸ‰ ç²¾åº¦å‘ä¸Šç‰ˆå®Œäº†: {result}")
        compare_results()
        
        print("\\nğŸ’¡ ã•ã‚‰ãªã‚‹æ”¹å–„æ¡ˆ:")
        print("1. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ (è¤‡æ•°ãƒ¢ãƒ‡ãƒ«çµ„ã¿åˆã‚ã›)")
        print("2. ãƒ‡ãƒ¼ã‚¿è¿½åŠ åé›†")
        print("3. ç–‘ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°")
        print("4. Knowledge Distillation")
        
    else:
        print("âŒ ç²¾åº¦å‘ä¸Šç‰ˆå¤±æ•—")

if __name__ == "__main__":
    main()