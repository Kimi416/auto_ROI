#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŒ…æ‹¬çš„ç—…å¤‰æ¤œå‡ºå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
å…¨1,047æšã®ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨ã—ãŸå®Œå…¨å­¦ç¿’
"""

import os
import cv2
import json
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from datetime import datetime
from tqdm import tqdm
import yaml
import random

class ComprehensiveLesionTrainer:
    def __init__(self, output_dir="comprehensive_lesion_training"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # PAD-UFES-20ã‚¯ãƒ©ã‚¹å®šç¾©
        self.pad_classes = ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']
        
        # ç—…å¤‰ã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°
        self.lesion_mapping = {
            'ADM': 'ACK',
            'Basal cell carcinoma': 'BCC',
            'Malignant melanoma': 'MEL',
            'Nevus': 'NEV',
            'Solar lentigo': 'SCC',
            'Seborrheic keratosis': 'SEK',
            'Ephelis': 'ACK',
            'Melasma': 'ACK'
        }
        
        print(f"ğŸ¯ åŒ…æ‹¬çš„ç—…å¤‰æ¤œå‡ºå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def create_comprehensive_dataset(self, source_dir="organized_advanced_masked"):
        """
        å…¨ã¦ã®ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        """
        print("\nğŸ“Š åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå…¨ç”»åƒä½¿ç”¨ï¼‰")
        print("=" * 60)
        
        dataset_dir = self.output_dir / "comprehensive_dataset"
        yolo_dir = dataset_dir / "yolo_format"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
        for split in ['train', 'val', 'test']:
            (yolo_dir / split / 'images').mkdir(parents=True, exist_ok=True)
            (yolo_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        source_path = Path(source_dir)
        all_data = []
        
        # å„ç—…å¤‰ã‚¿ã‚¤ãƒ—ã‹ã‚‰å…¨ã¦ã®ç”»åƒã‚’åé›†
        for lesion_dir in source_path.iterdir():
            if not lesion_dir.is_dir():
                continue
                
            lesion_type = lesion_dir.name
            mapped_class = self.lesion_mapping.get(lesion_type, 'ACK')
            
            # å…¨ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            image_files = list(lesion_dir.glob("*.jpg"))
            print(f"ğŸ“‚ åé›†ä¸­: {lesion_type} â†’ {mapped_class} ({len(image_files)}æš)")
            
            for img_path in image_files:
                all_data.append({
                    'path': img_path,
                    'class': mapped_class,
                    'original_type': lesion_type
                })
        
        print(f"\nğŸ“Š ç·åé›†ç”»åƒæ•°: {len(all_data)}æš")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã¨åˆ†å‰²ï¼ˆ7:2:1ï¼‰
        random.shuffle(all_data)
        total = len(all_data)
        train_end = int(total * 0.7)
        val_end = int(total * 0.9)
        
        splits = {
            'train': all_data[:train_end],
            'val': all_data[train_end:val_end],
            'test': all_data[val_end:]
        }
        
        print(f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
        print(f"  Train: {len(splits['train'])}æš")
        print(f"  Val: {len(splits['val'])}æš")
        print(f"  Test: {len(splits['test'])}æš")
        
        processed_count = 0
        
        for split_name, data in splits.items():
            print(f"\nğŸ”„ {split_name}ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­: {len(data)}ä»¶")
            
            for i, item in enumerate(tqdm(data, desc=f"Processing {split_name}")):
                try:
                    # ç”»åƒèª­ã¿è¾¼ã¿
                    img = cv2.imread(str(item['path']))
                    if img is None:
                        continue
                    
                    # ç”»åƒãƒªã‚µã‚¤ã‚º
                    img_resized = cv2.resize(img, (640, 640))
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆ
                    new_name = f"{item['class']}_{split_name}_{i:05d}.jpg"
                    
                    # ç”»åƒä¿å­˜
                    dst_img = yolo_dir / split_name / 'images' / new_name
                    cv2.imwrite(str(dst_img), img_resized)
                    
                    # YOLOã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆä¸­å¤®ã®80%ã«ç—…å¤‰ãŒã‚ã‚‹ã¨ä»®å®šï¼‰
                    class_id = self.pad_classes.index(item['class'])
                    annotation = f"{class_id} 0.5 0.5 0.8 0.8"
                    
                    label_path = yolo_dir / split_name / 'labels' / f"{item['class']}_{split_name}_{i:05d}.txt"
                    with open(label_path, 'w') as f:
                        f.write(annotation)
                    
                    processed_count += 1
                    
                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        yaml_config = {
            'path': str(yolo_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': len(self.pad_classes),
            'names': self.pad_classes
        }
        
        yaml_path = yolo_dir / 'comprehensive_dataset.yaml'
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_config, f, default_flow_style=False)
        
        print(f"\nâœ… åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {processed_count}ä»¶")
        print(f"ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {yaml_path}")
        
        return yaml_path, processed_count
    
    def train_comprehensive_model(self, yaml_path, epochs=30):
        """
        åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
        """
        print("\nğŸš€ åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        print("=" * 60)
        
        # YOLOv8sã§é«˜æ€§èƒ½è¨“ç·´
        model = YOLO('yolov8s.pt')
        
        # åŒ…æ‹¬çš„è¨­å®šã§è¨“ç·´å®Ÿè¡Œ
        results = model.train(
            data=yaml_path,
            epochs=epochs,
            imgsz=640,
            batch=16,
            name=f'comprehensive_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            patience=10,
            save=True,
            cache=False,  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
            device='mps',
            workers=4,
            project=self.output_dir / 'training_runs',
            
            # æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®š
            lr0=0.01,
            lrf=0.01,
            warmup_epochs=3,
            
            # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            degrees=15.0,
            translate=0.1,
            scale=0.5,
            fliplr=0.5,
            flipud=0.1,
            mixup=0.1,
            mosaic=1.0,
            
            # æœ€é©åŒ–
            optimizer='AdamW',
            close_mosaic=10
        )
        
        model_path = results.save_dir / 'weights' / 'best.pt'
        print(f"\nâœ… åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†!")
        print(f"ğŸ† ãƒ¢ãƒ‡ãƒ«: {model_path}")
        
        return model_path, results
    
    def comprehensive_test(self, model_path, test_images_dir, num_test=5):
        """
        åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
        """
        print("\nğŸ§ª åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 60)
        
        model = YOLO(model_path)
        test_results = []
        
        test_path = Path(test_images_dir)
        output_dir = self.output_dir / "comprehensive_test_results"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å„ç—…å¤‰ã‚¿ã‚¤ãƒ—ã‹ã‚‰ãƒ†ã‚¹ãƒˆ
        for lesion_dir in test_path.iterdir():
            if not lesion_dir.is_dir():
                continue
                
            lesion_type = lesion_dir.name
            expected_class = self.lesion_mapping.get(lesion_type, 'ACK')
            
            print(f"\nğŸ” ãƒ†ã‚¹ãƒˆä¸­: {lesion_type} (æœŸå¾…: {expected_class})")
            
            # å„ã‚¿ã‚¤ãƒ—ã‹ã‚‰æŒ‡å®šæ•°ã‚’ãƒ†ã‚¹ãƒˆ
            image_files = list(lesion_dir.glob("*.jpg"))[:num_test]
            
            for img_path in image_files:
                try:
                    # æ¨è«–å®Ÿè¡Œ
                    results = model(str(img_path), conf=0.2, save=True, save_dir=output_dir)
                    
                    detections = []
                    for result in results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                cls_id = int(box.cls[0])
                                conf = float(box.conf[0])
                                predicted_class = self.pad_classes[cls_id]
                                
                                detections.append({
                                    'class': predicted_class,
                                    'confidence': conf
                                })
                    
                    # çµæœè¨˜éŒ²
                    is_correct = any(d['class'] == expected_class for d in detections)
                    
                    test_results.append({
                        'image': img_path.name,
                        'expected_class': expected_class,
                        'original_type': lesion_type,
                        'detections': detections,
                        'correct': is_correct
                    })
                    
                    status = 'âœ…' if is_correct else 'âŒ'
                    det_str = ', '.join([f"{d['class']}({d['confidence']:.2f})" for d in detections])
                    print(f"  ğŸ“¸ {img_path.name}: {det_str} â†’ {status}")
                    
                except Exception as e:
                    print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ {img_path}: {e}")
        
        # çµ±è¨ˆè¨ˆç®—
        total_tests = len(test_results)
        correct_tests = sum(1 for r in test_results if r['correct'])
        accuracy = correct_tests / total_tests if total_tests > 0 else 0
        
        print(f"\nğŸ“Š åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"  æ­£è§£æ•°: {correct_tests}")
        print(f"  ç²¾åº¦: {accuracy:.3f} ({accuracy*100:.1f}%)")
        
        return accuracy, test_results
    
    def run_comprehensive_training(self, source_dir="organized_advanced_masked"):
        """
        åŒ…æ‹¬çš„å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’å®Ÿè¡Œ
        """
        print("ğŸ¯ åŒ…æ‹¬çš„ç—…å¤‰æ¤œå‡ºå­¦ç¿’é–‹å§‹")
        print("=" * 80)
        print("ğŸ“‹ åŒ…æ‹¬çš„ãƒ—ãƒ©ãƒ³:")
        print("  1. å…¨ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒï¼ˆ1,047æšï¼‰ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ")
        print("  2. åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´ (30ã‚¨ãƒãƒƒã‚¯)")
        print("  3. åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ")
        print("=" * 80)
        
        try:
            # åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
            dataset_yaml, data_count = self.create_comprehensive_dataset(source_dir)
            
            if data_count == 0:
                print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return None
            
            # åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model_path, training_results = self.train_comprehensive_model(dataset_yaml)
            
            # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            final_accuracy, test_results = self.comprehensive_test(model_path, source_dir)
            
            print("\nğŸ‰ åŒ…æ‹¬çš„å­¦ç¿’å®Œäº†!")
            print("=" * 80)
            print(f"ğŸ“Š æœ€çµ‚çµæœ:")
            print(f"  ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿æ•°: {data_count}")
            print(f"  æœ€çµ‚ç²¾åº¦: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)")
            print(f"ğŸ† æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {model_path}")
            print("=" * 80)
            
            return {
                'model_path': model_path,
                'final_accuracy': final_accuracy,
                'data_count': data_count,
                'test_results': test_results
            }
            
        except Exception as e:
            print(f"âŒ åŒ…æ‹¬çš„å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    trainer = ComprehensiveLesionTrainer()
    results = trainer.run_comprehensive_training()
    
    if results:
        print(f"\nâœ… åŒ…æ‹¬çš„å­¦ç¿’æˆåŠŸ!")
        print(f"ğŸ“ˆ é”æˆç²¾åº¦: {results['final_accuracy']:.3f}")
        print(f"ğŸ¯ å…¨ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨ã—ãŸç—…å¤‰è‡ªå‹•æ¤œå‡ºãŒå®Œæˆã—ã¾ã—ãŸï¼")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ”¹å–„: 80æš â†’ {results['data_count']}æš ({results['data_count']/80:.1f}å€)")
    else:
        print("âŒ åŒ…æ‹¬çš„å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()