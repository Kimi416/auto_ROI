#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
PAD-UFES-20ãƒ¢ãƒ‡ãƒ«ã‚’YOLOæŠ½å‡ºç—…å¤‰éƒ¨ã§å¼·åŒ–ã™ã‚‹è¿½åŠ å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
æŠ½å‡ºã•ã‚ŒãŸç—…å¤‰ROIã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹
"""

import os
import cv2
import json
import shutil
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from datetime import datetime
from tqdm import tqdm
import yaml

class EnhancedPADLesionTrainer:
    def __init__(self, base_model_path=None, output_dir="enhanced_pad_training"):
        """
        å¼·åŒ–å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        """
        self.base_model_path = base_model_path or "runs/detect/pad_ufes_20_realistic_20250805_174734/weights/best.pt"
        self.output_dir = Path(output_dir)
        self.pad_classes = ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']
        
        # ç—…å¤‰ã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°
        self.lesion_mapping = {
            'ADM': 'ACK',
            'Basal cell carcinoma': 'BCC',
            'Malignant melanoma': 'MEL', 
            'Nevus': 'NEV',
            'Solar lentigo': 'SCC',
            'Seborrheic keratosis': 'SEK',
            'Ephelis': 'ACK',
            'Melasma': 'ACK'
        }
        
        print(f"ğŸ¯ Enhanced PAD Lesion Trainer åˆæœŸåŒ–")
        print(f"ğŸ“‚ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: {self.base_model_path}")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def extract_lesions_for_training(self, source_images_dir, confidence_threshold=0.3):
        """
        å…ƒç”»åƒã‹ã‚‰ç—…å¤‰ã‚’æŠ½å‡ºã—ã¦è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        """
        print("ğŸ” YOLOç—…å¤‰æŠ½å‡ºã«ã‚ˆã‚‹è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä½œæˆé–‹å§‹...")
        
        source_path = Path(source_images_dir)
        extraction_dir = self.output_dir / "extracted_lesions"
        extraction_dir.mkdir(parents=True, exist_ok=True)
        
        # Enhanced PAD Lesion Extractorã‚’ä½¿ç”¨
        from enhanced_pad_lesion_extractor import EnhancedPADLesionExtractor
        extractor = EnhancedPADLesionExtractor()
        
        extracted_data = []
        
        # å„ç—…å¤‰ã‚¿ã‚¤ãƒ—ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†
        for lesion_dir in source_path.iterdir():
            if not lesion_dir.is_dir():
                continue
                
            lesion_type = lesion_dir.name
            mapped_type = self.lesion_mapping.get(lesion_type, 'ACK')
            
            print(f"ğŸ“‚ å‡¦ç†ä¸­: {lesion_type} -> {mapped_type}")
            
            # å„ç”»åƒã‚’å‡¦ç†ï¼ˆæ•°ã‚’åˆ¶é™ï¼‰
            image_files = list(lesion_dir.glob("*.jpg"))[:5]  # å„ã‚¿ã‚¤ãƒ—ã‹ã‚‰5æšã«åˆ¶é™
            
            for img_path in tqdm(image_files, desc=f"Extracting {lesion_type}"):
                try:
                    # ç—…å¤‰æŠ½å‡ºå®Ÿè¡Œ
                    lesions = extractor.extract_lesions_from_image(
                        img_path,
                        extraction_dir / lesion_type,
                        confidence_threshold=confidence_threshold
                    )
                    
                    # æŠ½å‡ºçµæœã‚’è¨˜éŒ²
                    for lesion in lesions:
                        extracted_data.append({
                            'original_image': str(img_path),
                            'lesion_image': lesion['filename'],
                            'true_class': mapped_type,
                            'predicted_class': lesion['class'],
                            'confidence': lesion['confidence'],
                            'bbox': lesion['bbox'],
                            'area': lesion['area']
                        })
                        
                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼å‡¦ç† {img_path}: {e}")
        
        # æŠ½å‡ºçµæœä¿å­˜
        extraction_summary = extraction_dir / "extraction_summary.json"
        with open(extraction_summary, 'w', encoding='utf-8') as f:
            json.dump(extracted_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç—…å¤‰æŠ½å‡ºå®Œäº†: {len(extracted_data)}å€‹ã®ç—…å¤‰ROIã‚’æŠ½å‡º")
        return extracted_data, extraction_dir
    
    def create_enhanced_dataset(self, extracted_data, extraction_dir):
        """
        æŠ½å‡ºã•ã‚ŒãŸç—…å¤‰ROIã‹ã‚‰YOLOå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        """
        print("ğŸ“Š æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­...")
        
        dataset_dir = self.output_dir / "enhanced_dataset"
        yolo_dir = dataset_dir / "yolo_format"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
        for split in ['train', 'val', 'test']:
            (yolo_dir / split / 'images').mkdir(parents=True, exist_ok=True)
            (yolo_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        np.random.shuffle(extracted_data)
        total = len(extracted_data)
        train_end = int(total * 0.7)
        val_end = int(total * 0.9)
        
        splits = {
            'train': extracted_data[:train_end],
            'val': extracted_data[train_end:val_end],
            'test': extracted_data[val_end:]
        }
        
        processed_count = 0
        
        for split_name, data in splits.items():
            print(f"\\n{split_name}ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­: {len(data)}ä»¶")
            
            for i, item in enumerate(tqdm(data, desc=f"Processing {split_name}")):
                try:
                    # å…ƒã®ç—…å¤‰ç”»åƒãƒ‘ã‚¹
                    lesion_img_name = item['lesion_image']
                    original_dir = Path(item['original_image']).parent.name
                    lesion_path = extraction_dir / original_dir / lesion_img_name
                    
                    if not lesion_path.exists():
                        continue
                    
                    # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«å
                    class_name = item['true_class']
                    new_name = f"{class_name}_{split_name}_{i:04d}.jpg"
                    
                    # ç”»åƒã‚’ã‚³ãƒ”ãƒ¼
                    dst_img = yolo_dir / split_name / 'images' / new_name
                    shutil.copy2(lesion_path, dst_img)
                    
                    # YOLOã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆç—…å¤‰ROIç”»åƒãªã®ã§å…¨ä½“ãŒç—…å¤‰ï¼‰
                    class_id = self.pad_classes.index(class_name)
                    annotation = f"{class_id} 0.5 0.5 0.8 0.8"  # ä¸­å¤®80%ãŒç—…å¤‰
                    
                    label_path = yolo_dir / split_name / 'labels' / f"{class_name}_{split_name}_{i:04d}.txt"
                    with open(label_path, 'w') as f:
                        f.write(annotation)
                    
                    processed_count += 1
                    
                except Exception as e:
                    print(f"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        yaml_config = {
            'path': str(yolo_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': len(self.pad_classes),
            'names': self.pad_classes
        }
        
        yaml_path = yolo_dir / 'enhanced_dataset.yaml'
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_config, f, default_flow_style=False)
        
        print(f"âœ… æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {processed_count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
        print(f"ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {yaml_path}")
        
        return yaml_path, processed_count
    
    def fine_tune_model(self, yaml_path, epochs=50, batch_size=16):
        """
        PAD-UFES-20ãƒ¢ãƒ‡ãƒ«ã‚’æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
        """
        print("ğŸš€ PAD-UFES-20ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
        
        # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        if Path(self.base_model_path).exists():
            model = YOLO(self.base_model_path)
            print(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: {self.base_model_path}")
        else:
            print("âš ï¸ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚YOLOv8nã‹ã‚‰é–‹å§‹...")
            model = YOLO('yolov8n.pt')
        
        # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        results = model.train(
            data=yaml_path,
            epochs=epochs,
            imgsz=640,
            batch=batch_size,
            name=f'enhanced_pad_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            patience=10,
            save=True,
            cache=True,
            device='mps',
            workers=2,  # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’æ¸›ã‚‰ã™
            project=self.output_dir / 'training_runs',
            # å­¦ç¿’ç‡ã‚’ä¸‹ã’ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
            lr0=0.001,  # ä½ã„å­¦ç¿’ç‡
            lrf=0.001,
            warmup_epochs=5,
            # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’èª¿æ•´
            degrees=5.0,
            translate=0.05,
            scale=0.1,
            fliplr=0.5,
            mixup=0.1,
            # NMSã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–
            agnostic_nms=True,
            max_det=100  # æœ€å¤§æ¤œå‡ºæ•°ã‚’åˆ¶é™
        )
        
        print("âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†!")
        return results
    
    def evaluate_enhanced_model(self, model_path, test_images_dir):
        """
        å¼·åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡
        """
        print("ğŸ“Š å¼·åŒ–ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡é–‹å§‹...")
        
        model = YOLO(model_path)
        test_results = []
        
        test_path = Path(test_images_dir)
        
        for lesion_dir in test_path.iterdir():
            if not lesion_dir.is_dir():
                continue
                
            lesion_type = lesion_dir.name
            mapped_type = self.lesion_mapping.get(lesion_type, 'ACK')
            
            # ãƒ†ã‚¹ãƒˆç”»åƒã‚’å‡¦ç†
            image_files = list(lesion_dir.glob("*.jpg"))[:5]  # å„ã‚¿ã‚¤ãƒ—ã‹ã‚‰5æšãƒ†ã‚¹ãƒˆ
            
            for img_path in image_files:
                results = model(img_path, conf=0.25, save=False)
                
                detected_classes = []
                confidences = []
                
                for result in results:
                    if result.boxes:
                        for box in result.boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            class_name = self.pad_classes[cls_id]
                            
                            detected_classes.append(class_name)
                            confidences.append(conf)
                
                test_results.append({
                    'image': img_path.name,
                    'true_class': mapped_type,
                    'detected_classes': detected_classes,
                    'confidences': confidences,
                    'correct': mapped_type in detected_classes if detected_classes else False
                })
        
        # ç²¾åº¦è¨ˆç®—
        correct_predictions = sum(1 for r in test_results if r['correct'])
        total_predictions = len(test_results)
        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
        
        print(f"ğŸ“ˆ è©•ä¾¡çµæœ:")
        print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {total_predictions}")
        print(f"  æ­£è§£æ•°: {correct_predictions}")
        print(f"  ç²¾åº¦: {accuracy:.3f} ({accuracy*100:.1f}%)")
        
        # çµæœä¿å­˜
        evaluation_path = self.output_dir / "evaluation_results.json"
        with open(evaluation_path, 'w', encoding='utf-8') as f:
            json.dump({
                'accuracy': accuracy,
                'correct_predictions': correct_predictions,
                'total_predictions': total_predictions,
                'detailed_results': test_results
            }, f, ensure_ascii=False, indent=2)
        
        return accuracy, test_results
    
    def run_complete_enhancement(self, source_images_dir, confidence_threshold=0.3, epochs=30):
        """
        å®Œå…¨ãªå¼·åŒ–å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
        """
        print("ğŸ¯ PAD-UFES-20ãƒ¢ãƒ‡ãƒ«å¼·åŒ–ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")
        print("=" * 60)
        
        # 1. ç—…å¤‰æŠ½å‡º
        extracted_data, extraction_dir = self.extract_lesions_for_training(
            source_images_dir, confidence_threshold
        )
        
        if len(extracted_data) == 0:
            print("âŒ æŠ½å‡ºã•ã‚ŒãŸç—…å¤‰ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # 2. æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        yaml_path, data_count = self.create_enhanced_dataset(extracted_data, extraction_dir)
        
        if data_count == 0:
            print("âŒ å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        training_results = self.fine_tune_model(yaml_path, epochs=epochs)
        
        # 4. æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹å–å¾—
        best_model_path = training_results.save_dir / 'weights' / 'best.pt'
        
        # 5. æ€§èƒ½è©•ä¾¡
        accuracy, test_results = self.evaluate_enhanced_model(
            best_model_path, source_images_dir
        )
        
        print(f"\\nğŸ‰ PAD-UFES-20ãƒ¢ãƒ‡ãƒ«å¼·åŒ–å®Œäº†!")
        print(f"ğŸ“Š æœ€çµ‚ç²¾åº¦: {accuracy:.3f} ({accuracy*100:.1f}%)")
        print(f"ğŸ† å¼·åŒ–ãƒ¢ãƒ‡ãƒ«: {best_model_path}")
        
        return {
            'model_path': best_model_path,
            'accuracy': accuracy,
            'data_count': data_count,
            'training_results': training_results
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¯ Enhanced PAD-UFES-20 Lesion Trainer")
    print("=" * 50)
    
    # æ—¢å­˜ã®PAD-UFES-20ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    base_model = "runs/detect/pad_ufes_20_realistic_20250805_174734/weights/best.pt"
    
    trainer = EnhancedPADLesionTrainer(base_model_path=base_model)
    
    # å¼·åŒ–å­¦ç¿’å®Ÿè¡Œ
    results = trainer.run_complete_enhancement(
        source_images_dir="organized_advanced_masked",
        confidence_threshold=0.4,  # é«˜å“è³ªãªç—…å¤‰ã®ã¿ä½¿ç”¨
        epochs=25
    )
    
    if results:
        print(f"\\nâœ… å¼·åŒ–å­¦ç¿’æˆåŠŸ!")
        print(f"ğŸ“ˆ ç²¾åº¦å‘ä¸Š: {results['accuracy']:.3f}")
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {results['model_path']}")
    else:
        print("âŒ å¼·åŒ–å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()