#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ”¹è‰¯ç‰ˆæ®µéšçš„ç—…å¤‰æ¤œå‡ºå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
1. PAD-UFES-20ã§åŸºç¤å­¦ç¿’
2. ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‚’ç›´æ¥ä½¿ç”¨ã—ã¦ROIå­¦ç¿’
3. åˆè¦‹ç”»åƒã§ã®ç—…å¤‰è‡ªå‹•æ¤œå‡º
"""

import os
import cv2
import json
import shutil
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from datetime import datetime
from tqdm import tqdm
import yaml
import random

class ImprovedProgressiveLesionTrainer:
    def __init__(self, output_dir="improved_progressive_training"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # PAD-UFES-20ã‚¯ãƒ©ã‚¹å®šç¾©
        self.pad_classes = ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']
        
        # ç—…å¤‰ã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°
        self.lesion_mapping = {
            'ADM': 'ACK',
            'Basal cell carcinoma': 'BCC',
            'Malignant melanoma': 'MEL',
            'Nevus': 'NEV',
            'Solar lentigo': 'SCC',
            'Seborrheic keratosis': 'SEK',
            'Ephelis': 'ACK',
            'Melasma': 'ACK'
        }
        
        print(f"ğŸ¯ Improved Progressive Lesion Trainer åˆæœŸåŒ–")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def create_roi_extraction_dataset(self, source_dir, samples_per_class=15):
        """
        ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‹ã‚‰ç›´æ¥ROIã‚’æŠ½å‡ºã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        """
        print("\nğŸ¨ ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒROIæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ")
        print("=" * 60)
        
        roi_dir = self.output_dir / "roi_dataset"
        yolo_dir = roi_dir / "yolo_format"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
        for split in ['train', 'val', 'test']:
            (yolo_dir / split / 'images').mkdir(parents=True, exist_ok=True)
            (yolo_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        source_path = Path(source_dir)
        all_data = []
        
        # å„ç—…å¤‰ã‚¿ã‚¤ãƒ—ã‹ã‚‰ç”»åƒã‚’åé›†
        for lesion_dir in source_path.iterdir():
            if not lesion_dir.is_dir():
                continue
                
            lesion_type = lesion_dir.name
            mapped_class = self.lesion_mapping.get(lesion_type, 'ACK')
            
            print(f"ğŸ“‚ åé›†ä¸­: {lesion_type} â†’ {mapped_class}")
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            image_files = list(lesion_dir.glob("*.jpg"))
            selected_images = random.sample(image_files, min(samples_per_class, len(image_files)))
            
            for img_path in selected_images:
                all_data.append({
                    'path': img_path,
                    'class': mapped_class,
                    'original_type': lesion_type
                })
        
        print(f"ğŸ“Š ç·åé›†ç”»åƒæ•°: {len(all_data)}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã¨åˆ†å‰²
        random.shuffle(all_data)
        total = len(all_data)
        train_end = int(total * 0.7)
        val_end = int(total * 0.9)
        
        splits = {
            'train': all_data[:train_end],
            'val': all_data[train_end:val_end],
            'test': all_data[val_end:]
        }
        
        processed_count = 0
        
        for split_name, data in splits.items():
            print(f"\nğŸ“‹ {split_name}ãƒ‡ãƒ¼ã‚¿å‡¦ç†: {len(data)}ä»¶")
            
            for i, item in enumerate(tqdm(data, desc=f"ROI {split_name}")):
                try:
                    # ç”»åƒèª­ã¿è¾¼ã¿
                    img = cv2.imread(str(item['path']))
                    if img is None:
                        continue
                    
                    # ç”»åƒã‚µã‚¤ã‚ºå–å¾—
                    h, w = img.shape[:2]
                    
                    # ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‹ã‚‰ç—…å¤‰é ˜åŸŸã‚’è‡ªå‹•æ¤œå‡º
                    lesion_rois = self.extract_lesion_regions(img)
                    
                    # ROIãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã¯ä¸­å¤®ã®å¤§ããªé ˜åŸŸã‚’ä½¿ç”¨
                    if not lesion_rois:
                        center_x, center_y = w // 2, h // 2
                        roi_size = min(w, h) // 2
                        lesion_rois = [{
                            'x': max(0, center_x - roi_size // 2),
                            'y': max(0, center_y - roi_size // 2),
                            'w': min(roi_size, w - max(0, center_x - roi_size // 2)),
                            'h': min(roi_size, h - max(0, center_y - roi_size // 2))
                        }]
                    
                    # å„ROIã‚’ä¿å­˜
                    for roi_idx, roi in enumerate(lesion_rois):
                        # ROIæŠ½å‡º
                        x, y, roi_w, roi_h = roi['x'], roi['y'], roi['w'], roi['h']
                        roi_img = img[y:y+roi_h, x:x+roi_w]
                        
                        if roi_img.size == 0:
                            continue
                        
                        # 640x640ã«ãƒªã‚µã‚¤ã‚º
                        roi_resized = cv2.resize(roi_img, (640, 640))
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆ
                        new_name = f"roi_{split_name}_{i:04d}_{roi_idx}.jpg"
                        
                        # ç”»åƒä¿å­˜
                        dst_img = yolo_dir / split_name / 'images' / new_name
                        cv2.imwrite(str(dst_img), roi_resized)
                        
                        # YOLOã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆROIå…¨ä½“ãŒç—…å¤‰ï¼‰
                        class_id = self.pad_classes.index(item['class'])
                        annotation = f"{class_id} 0.5 0.5 0.9 0.9"  # 90%ãŒç—…å¤‰
                        
                        label_path = yolo_dir / split_name / 'labels' / f"roi_{split_name}_{i:04d}_{roi_idx}.txt"
                        with open(label_path, 'w') as f:
                            f.write(annotation)
                        
                        processed_count += 1
                        
                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        yaml_config = {
            'path': str(yolo_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': len(self.pad_classes),
            'names': self.pad_classes
        }
        
        yaml_path = yolo_dir / 'roi_dataset.yaml'
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_config, f, default_flow_style=False)
        
        print(f"\nâœ… ROIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {processed_count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ")
        print(f"ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {yaml_path}")
        
        return yaml_path, processed_count
    
    def extract_lesion_regions(self, image):
        """
        ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‹ã‚‰ç—…å¤‰é ˜åŸŸã‚’æŠ½å‡º
        """
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å¹³å¦åŒ–
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        # ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges = cv2.Canny(enhanced, 30, 100)
        
        # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
        
        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # é©åˆ‡ãªã‚µã‚¤ã‚ºã®é ˜åŸŸã‚’é¸æŠ
        lesion_rois = []
        h, w = image.shape[:2]
        min_area = (w * h) * 0.01  # ç”»åƒã®1%ä»¥ä¸Š
        max_area = (w * h) * 0.3   # ç”»åƒã®30%ä»¥ä¸‹
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if min_area < area < max_area:
                x, y, cw, ch = cv2.boundingRect(contour)
                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒã‚§ãƒƒã‚¯
                aspect_ratio = float(cw) / ch
                if 0.3 < aspect_ratio < 3.0:
                    lesion_rois.append({'x': x, 'y': y, 'w': cw, 'h': ch})
        
        # é¢ç©ã§ä¸¦ã³æ›¿ãˆã¦ä¸Šä½3ã¤ã¾ã§
        lesion_rois.sort(key=lambda r: r['w'] * r['h'], reverse=True)
        return lesion_rois[:3]
    
    def train_comprehensive_model(self, yaml_path, epochs=40):
        """
        åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«è¨“ç·´
        """
        print("\nğŸš€ åŒ…æ‹¬çš„ç—…å¤‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        print("=" * 60)
        
        # YOLOv8sã‹ã‚‰é–‹å§‹ï¼ˆã‚ˆã‚Šé«˜æ€§èƒ½ï¼‰
        model = YOLO('yolov8s.pt')
        
        # è¨“ç·´å®Ÿè¡Œ
        results = model.train(
            data=yaml_path,
            epochs=epochs,
            imgsz=640,
            batch=16,
            name=f'comprehensive_lesion_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            patience=15,
            save=True,
            cache=True,
            device='mps',
            workers=4,
            project=self.output_dir / 'training_runs',
            
            # æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®š
            lr0=0.01,
            lrf=0.01,
            warmup_epochs=5,
            
            # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            degrees=20.0,
            translate=0.1,
            scale=0.5,
            fliplr=0.5,
            flipud=0.2,    # åŒ»ç™‚ç”»åƒã§ã¯ä¸Šä¸‹åè»¢ã‚‚æœ‰åŠ¹
            mixup=0.15,
            mosaic=1.0,
            
            # æœ€é©åŒ–
            optimizer='AdamW',
            close_mosaic=15
        )
        
        model_path = results.save_dir / 'weights' / 'best.pt'
        print(f"\nâœ… åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†!")
        print(f"ğŸ† ãƒ¢ãƒ‡ãƒ«: {model_path}")
        
        return model_path, results
    
    def test_on_unseen_images(self, model_path, test_images_dir, num_test_per_class=5):
        """
        åˆè¦‹ç”»åƒã§ã®ç—…å¤‰æ¤œå‡ºãƒ†ã‚¹ãƒˆ
        """
        print("\nğŸ§ª åˆè¦‹ç”»åƒã§ã®ç—…å¤‰æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
        print("=" * 60)
        
        model = YOLO(model_path)
        test_results = []
        
        test_path = Path(test_images_dir)
        output_dir = self.output_dir / "test_results"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒã‚’é¸æŠ
        for lesion_dir in test_path.iterdir():
            if not lesion_dir.is_dir():
                continue
                
            lesion_type = lesion_dir.name
            expected_class = self.lesion_mapping.get(lesion_type, 'ACK')
            
            print(f"\nğŸ” ãƒ†ã‚¹ãƒˆä¸­: {lesion_type} (æœŸå¾…ã‚¯ãƒ©ã‚¹: {expected_class})")
            
            # å„ã‚¿ã‚¤ãƒ—ã‹ã‚‰æŒ‡å®šæ•°ã‚’ãƒ†ã‚¹ãƒˆ
            image_files = list(lesion_dir.glob("*.jpg"))
            test_images = random.sample(image_files, min(num_test_per_class, len(image_files)))
            
            for img_path in test_images:
                try:
                    # æ¨è«–å®Ÿè¡Œ
                    results = model(str(img_path), conf=0.25, save=True, save_dir=output_dir)
                    
                    detections = []
                    for result in results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                cls_id = int(box.cls[0])
                                conf = float(box.conf[0])
                                predicted_class = self.pad_classes[cls_id]
                                x1, y1, x2, y2 = map(int, box.xyxy[0])
                                
                                detections.append({
                                    'class': predicted_class,
                                    'confidence': conf,
                                    'bbox': [x1, y1, x2, y2]
                                })
                    
                    # çµæœè¨˜éŒ²
                    is_correct = any(d['class'] == expected_class for d in detections)
                    
                    test_results.append({
                        'image': img_path.name,
                        'expected_class': expected_class,
                        'original_type': lesion_type,
                        'detections': detections,
                        'detection_count': len(detections),
                        'correct': is_correct
                    })
                    
                    status = 'âœ…' if is_correct else 'âŒ'
                    print(f"  ğŸ“¸ {img_path.name}: {len(detections)}å€‹æ¤œå‡º, æ­£è§£: {status}")
                    
                except Exception as e:
                    print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ {img_path}: {e}")
        
        # çµ±è¨ˆè¨ˆç®—
        total_tests = len(test_results)
        correct_tests = sum(1 for r in test_results if r['correct'])
        accuracy = correct_tests / total_tests if total_tests > 0 else 0
        
        print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"  æ­£è§£æ•°: {correct_tests}")
        print(f"  ç²¾åº¦: {accuracy:.3f} ({accuracy*100:.1f}%)")
        
        # çµæœä¿å­˜
        results_path = self.output_dir / "test_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'model_path': str(model_path),
                'accuracy': accuracy,
                'total_tests': total_tests,
                'correct_tests': correct_tests,
                'detailed_results': test_results
            }, f, ensure_ascii=False, indent=2)
        
        return accuracy, test_results
    
    def run_improved_training(self, source_dir="organized_advanced_masked"):
        """
        æ”¹è‰¯ã•ã‚ŒãŸæ®µéšçš„å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’å®Ÿè¡Œ
        """
        print("ğŸ¯ Improved Progressive Lesion Detection Training é–‹å§‹")
        print("=" * 80)
        print("ğŸ“‹ æ”¹è‰¯ãƒ—ãƒ©ãƒ³:")
        print("  1. ãƒã‚¹ã‚¯æ¸ˆã¿ç”»åƒã‹ã‚‰ç›´æ¥ROIæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ")
        print("  2. åŒ…æ‹¬çš„ç—…å¤‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«è¨“ç·´")
        print("  3. åˆè¦‹ç”»åƒã§ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
        print("=" * 80)
        
        try:
            # ROIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
            roi_yaml, roi_count = self.create_roi_extraction_dataset(source_dir)
            
            if roi_count == 0:
                print("âŒ ROIãƒ‡ãƒ¼ã‚¿ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return None
            
            # åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model_path, training_results = self.train_comprehensive_model(roi_yaml)
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            final_accuracy, test_results = self.test_on_unseen_images(model_path, source_dir)
            
            print("\nğŸ‰ Improved Progressive Training å®Œäº†!")
            print("=" * 80)
            print(f"ğŸ“Š æœ€çµ‚çµæœ:")
            print(f"  ROIãƒ‡ãƒ¼ã‚¿æ•°: {roi_count}")
            print(f"  æœ€çµ‚ç²¾åº¦: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)")
            print(f"ğŸ† æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {model_path}")
            print("=" * 80)
            
            return {
                'model_path': model_path,
                'final_accuracy': final_accuracy,
                'roi_count': roi_count,
                'test_results': test_results
            }
            
        except Exception as e:
            print(f"âŒ Improved Progressive Training ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    trainer = ImprovedProgressiveLesionTrainer()
    results = trainer.run_improved_training()
    
    if results:
        print(f"\nâœ… æ”¹è‰¯æ®µéšçš„å­¦ç¿’æˆåŠŸ!")
        print(f"ğŸ“ˆ é”æˆç²¾åº¦: {results['final_accuracy']:.3f}")
        print(f"ğŸ¯ åˆè¦‹ç”»åƒã§ã®ç—…å¤‰è‡ªå‹•æ¤œå‡ºãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸï¼")
    else:
        print("âŒ æ”¹è‰¯æ®µéšçš„å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()